package com.djj.languagepoints.chapter6;

/**
 并发是两个任务共享时间段
 并行则是两个任务在同一时间发生

 比如运行在多核 CPU上。如果一个程序要运行两个任务，并且只有一个 CPU 给它们分配了不同的时间片，
 那么这就是并发，而不是并行。

 并行化：
 指为缩短任务执行时间，将一个任务分解成几部分，然后并行执行。
 这和顺序执行的任务量是一样的，区别就像用更多的马来拉车，花费的时间自然减少了。
 实际上，和顺序执行相比，并行化执行任务时，CPU 承载的工作量更大。

 任务并行化
 数据并行化

 【限制】让已有代码并行化运行，但前提是代码写得符合约定
 reduce 方法：为了让其在并行化时能工作正常，初值必须为组合函数的恒等值。拿恒等值和其他值做 reduce 操作时，其他值保持不变。
 比如，使用reduce 操作求和，组合函数为 (acc, element) -> acc + element ，则其初值必须为 0， 因为任何数字加 0，值不变。
 reduce 操作的另一个限制是组合操作必须符合结合律。这意味着只要序列的值不变，组合操作的顺序不重要。

 要避免的是持有锁，流框架会在需要时，自己处理同步操作，因此程序员没有必要为自己的数据结构加锁。

 在要对流求值时，不能同时处于两种模式，要么是并行的，要么是串行的。
 如果同时调用了 parallel 和 sequential 方法，最后调用的那个方法起效。

 【性能】
 数据大小：
 输入数据的大小会影响并行化处理对性能的提升。将问题分解之后并行化处理，再将结果合并会带来额外的开销。
 因此只有数据足够大、每个数据处理管道花费的时间足够多时，并行化处理才有意义。

 源数据结构：
 每个管道的操作都基于一些初始数据源，通常是集合。
 将不同的数据源分割相对容易，这里的开销影响了在管道中并行处理数据时到底能带来多少性能上的提升。
    性能好：
    ArrayList 、数组或 IntStream.range ，这些数据结构支持随机读取，也就是说它们能轻而易举地被任意分解。
    性能一般：
    HashSet 、 TreeSet ，这些数据结构不易公平地被分解，但是大多数时候分解是可能的。
    性能差：
    有些数据结构难于分解，比如，可能要花 O(N) 的时间复杂度来分解问题。
    其中包括LinkedList ，对半分解太难了。还有 Streams.iterate 和 BufferedReader.lines ，它们长度未知，因此很难预测该在哪里分解。

 装箱：
 处理基本类型比处理装箱类型要快。

 核的数量：
 极端情况下，只有一个核，因此完全没必要并行化。显然，拥有的核越多，获得潜在性能提升的幅度就越大。
 在实践中，核的数量不单指你的机器上有多少核，更是指运行时你的机器能使用多少核。
 这也就是说同时运行的其他进程，或者线程关联性（强制线程在某些核或 CPU 上运行）会影响性能。

 单元处理开销：
 比如数据大小，这是一场并行执行花费时间和分解合并操作开销之间的战争。
 花在流中每个元素身上的时间越长，并行操作带来的性能提升越明显。

 【分解和合并实例】
 private int addIntegers(List<Integer> values) {
     return values.parallelStream()
             .mapToInt(i -> i)
             .sum();
 }
 在底层，并行流还是沿用了 fork/join 框架。fork 递归式地分解问题，然后每段并行执行，最终由 join 合并结果，返回最后的值。


 两种不同的操作：无状态的和有状态的
 无状态操作整个过程中不必维护状态，有状态操作则有维护状态所需的开销和限制。
 如果能避开有状态，选用无状态操作，就能获得更好的并行性能。
 无状态操作包括 map 、filter 和 flatMap ，
 有状态操作包括 sorted 、 distinct 和 limit 。

 */
